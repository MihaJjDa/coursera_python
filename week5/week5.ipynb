{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неделя 5 \n",
    "# Многопоточное и асинхронное программирование\n",
    "\n",
    "## 5.1. Введение\n",
    "\n",
    "Асинхронное и многопоточное программирование — это достаточно сложная тема для изучения. Наше обучение будет разбито на три основных части. В первой части мы рассмотрим выполнение \"синхронных программ\", и посмотрим на примеры их выполнения в процессах и потоках. Далее мы погрузимся в то, как устроены socket-ы, и рассмотрим выполнение различных сетевых запросов. В заключительной части нашего обучения мы\n",
    "углубимся в то, как устроены генераторы и корутины в языке Python и рассмотрим примеры работы с framework-ом asyncio. Полученные знания могут оказаться полезными для вас, даже если вы не разрабатываете на языке Python. Пройдя обучение, вы сможете увидеть, насколько это легко и удобно сделано в Python и, возможно, сравнить с другими языками программирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Процессы и потоки\n",
    "\n",
    "### 5.2.1. Процесс и его характеристики\n",
    "\n",
    "Процесс — это программа, которая запущена в оперативной памяти компьютера. Другими словами, процесс — это набор инструкций, которые выполняются последовательно.\n",
    "\n",
    "Каждый процесс, который запущен в операционной системе, имеет свои характеристики. Одна из главных характеристик — это идентификатор процесса или PID. Кроме того, каждый процесс занимает некий объем оперативной памяти, которую он запрашивает у системы. Система возвращает запрошенный объём памяти процессу и аллоцирует её.\n",
    "Также у процесса есть стек — он используется для вызова функций и создания локальных переменных у этих функций. И, наконец, у каждого процесса есть список открытых файлов, стандартный ввод и стандартный вывод.\n",
    "\n",
    "Характеристики процесса:\n",
    "\n",
    "- Идентификатор процесса, PID\n",
    "- Объем оперативной памяти\n",
    "- Стек\n",
    "- Список открытых файлов\n",
    "- Ввод/вывод\n",
    "\n",
    "В следующих примерах мы будем использовать операционную систему класса Linux и Python 3.\n",
    "\n",
    "Давайте попробуем узнать, какие процессы запущены в операционной системе. Для этого нам потребуется консоль и команда top — она отображает список процессов, которые сейчас функционируют в операционной системе. В виде колонок в таблице мы видим\n",
    "характеристики процессов: \n",
    "\n",
    "```bash\n",
    "top\n",
    "```\n",
    "\n",
    "В таблице указан PID (идентификатор процесса), пользователь, из-под которого был запущен процесс (определяет права, которые будут доступны этому процессу в операционной системе), размер виртуальной и физической памяти, процент используемого времени процессора и т.д. Как мы видим, процессов в операционной системе достаточно много, и все они работают на первый взгляд параллельно. На самом деле это не так. Планировщик операционной системы выделяет небольшой квант времени каждому процессу, исполняет его и затем происходит переключение между процессами. Таким образом, процессы выполняются последовательно, но из-за того, что квант времени небольшой, нам кажется, что все они выполняются параллельно.\n",
    "\n",
    "Давайте попробуем запустить наш первый Python процесс и изучим его характеристики средствами операционной системы. Сначала импортируем два модуля — time и os. Затем при помощи вызова функции модуля os.getpid мы получаем идентификатор процесса, запоминаем его в переменную pid и в бесконечном цикле выводим PID нашего\n",
    "процесса и системное время каждые 2 секунды:\n",
    "\n",
    "```python\n",
    "# ex1.py\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "pid = os.getpid()\n",
    "\n",
    "while True:\n",
    "    print(pid, time.time())\n",
    "    time.sleep(2)\n",
    "    \n",
    "```\n",
    "\n",
    "```bash\n",
    "python ex1.py\n",
    "```\n",
    "\n",
    "Мы видим, что запустился процесс. Он вывел pid, системное время и продолжает это делать бесконечно в цикле. Давайте попробуем найти наш процесс в списке всех процессов. Для этого нам поможет команда ps с флагами aux (подробную информацию о флагах можно посмотреть в документации). Эта команда отобразит список всех процессов. Для того чтобы найти конкретно наш процесс, можно отфильтровать выдачу ps aux\n",
    "при помощи команды grep. Мы увидим наш процесс (в данном случае в первой строчке):\n",
    "\n",
    "```\n",
    "ps aux\n",
    "\n",
    "ps aux | grep ex1.py\n",
    "```\n",
    "\n",
    "Чтобы посмотреть название характеристик, можно вывести первую строчку от результатов вывода ps при помощи следующей команды:\n",
    "Итак, процесс с PID-ом виден в результатах вывода команды ps. Он потребляет немного центрального процессора и занимает немного физической памяти. Также видим командную строчку, при помощи которой он был запущен (python3 ex1.py).\n",
    "\n",
    "Какую последовательность команд выполняет наш процесс? Вообще, когда процессы выполняются в операционной системе, они делают системные вызовы. Системные вызовы выполняет непосредственно ядро операционной системы, а результаты этих системных вызовов возвращаются к процессу, который их вызвал. Например, вывод в консоль, или стандартный вывод — это системный вызов. Чтобы посмотреть, какие системные вызовы делает наш процесс, можно воспользоваться командой strace, указав ей PID нашего процесса (для этой команды нужны дополнительные права):\n",
    "\n",
    "```bash\n",
    "sudo strace -p PID\n",
    "```\n",
    "\n",
    "В результате видим, что вызывается системный вызов write. У него в аргументах есть файловый дескриптор 1 — стандартный вывод. Также видим, что в стандартный вывод попадает PID нашего процесса и системное время, а для вызова sleep используются другие дополнительные системные вызовы. Для выхода используем Ctrl+C.\n",
    "\n",
    "Итак, мы узнали, что процесс во время исполнения общается с операционной системой при помощи системных вызовов. Давайте посмотрим на список файлов, которые открыты в нашем процессе. Для этого можно воспользоваться командой lsof, указав PID процесса.\n",
    "\n",
    "```bash\n",
    "lsof -p PID\n",
    "```\n",
    "\n",
    "Мы увидим, что процесс использует множество Python-библиотек. Но\n",
    "самое главное, что нас сейчас интересует, — это стандартный поток ввода, вывода и поток ошибок (файловые дескрипторы 0, 1 и 2).\n",
    "\n",
    "Мы видим, что эти файловые дескрипторы равны терминалу. Если мы будем делать стандартный вывод в файл, мы обнаружим, что стандартный вывод у нашего процесса поменялся на файл:\n",
    "\n",
    "```python\n",
    "python3 exq.py > log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Создание процессов\n",
    "\n",
    "Поговорим про создание процессов в Python. В этом разделе мы узнаем, как создать дочерний процесс, как работает системный вызов fork, а также рассмотрим примеры создания процессов при помощи модуля multiprocessing.\n",
    "\n",
    "Процесс в операционной системе создается при помощи системного вызова fork. Давайте рассмотрим программу, которая создает дочерний процесс при помощи системного вызова fork. Импортируем пару модулей time и os, затем вызываем системный вызов fork:\n",
    "\n",
    "```python\n",
    "# ex2.py\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "pid = os.fork()\n",
    "if pid == 0:\n",
    "    # дочерний процесс\n",
    "    while True:\n",
    "        print(\"child:\", os.getpid())\n",
    "        time.sleep(5)\n",
    "else:\n",
    "    # родительский процесс\n",
    "    print(\"parent:\", os.getpid())\n",
    "    os.wait()\n",
    "```\n",
    "\n",
    "```bash\n",
    "python3 ex2.py\n",
    "```\n",
    "\n",
    "Системный вызов fork создает точную копию родительского процесса. Это означает, что вся память, все файловые дескрипторы и все ресурсы, которые были доступны в родительском процессе, будут целиком и полностью скопированы в дочерний процесс. С того момента, как системный вызов fork отработал, у нас имеется два одинаковых процесса в операционной системе. Единственное отличие заключается в том, что системный вызов fork в родительский процесс вернет PID дочернего процесса, а в дочернем процессе переменная pid будет равна нулю. Код в блоке if будет исполнен в дочернем процессе, а код, который находится за веткой else, будет исполнен в родительском процессе.\n",
    "\n",
    "Также в родительском процессе мы вызываем системный вызов os.wait, это еще один дополнительный системный вызов и он позволяет нам дожидаться завершения созданного дочернего процесса. А в дочернем процессе в бесконечном цикле выводится PID этого процесса каждые пять секунд.\n",
    "\n",
    "Можно отобразить результаты команды ps в иерархическом виде, чтобы посмотреть, какой из процессов родительский, а какой дочерний. Делается это при помощи дополнительного флага f:\n",
    "\n",
    "```bash\n",
    "ps aux | grep ex2.py\n",
    "\n",
    "ps axf | grep ex2.py\n",
    "\n",
    "```\n",
    "\n",
    "Если мы вызовем команду strace, увидим, что наш созданный дочерний процесс делает системный вызов write и выводит информацию в стандартный поток вывода. А родительский процесс сделал системный вызов wait, и операционная система сама оповестит его о том, когда дочерний процесс завершится.\n",
    "\n",
    "```bash\n",
    "sudo strace -p PID\n",
    "```\n",
    "\n",
    "Давайте остановимся ещё раз на памяти в родительском и дочернем процессах и рассмотрим пример. Итак, у нас есть программа, мы объявили в ней переменную foo, присвоили ей значение \"bar\" и делаем системный вызов fork:\n",
    "\n",
    "```python\n",
    "# ex3.py\n",
    "\n",
    "import os\n",
    "\n",
    "foo = \"bar\"\n",
    "\n",
    "if os.fork() == 0:\n",
    "    # дочерний процесс\n",
    "    foo = \"baz\"\n",
    "    print(\"child:\", foo)\n",
    "else:\n",
    "    # родительский процесс\n",
    "    print(\"parent:\", foo)\n",
    "    os.wait()\n",
    "```\n",
    "\n",
    "```bash\n",
    "python ex3.py\n",
    "```\n",
    "\n",
    "После того, как отработал системный вызов fork, как уже было сказано, вся память целиком и полностью будет скопирована из родительского процесса в дочерний. Значит, переменная foo будет доступна в дочернем процессе со значением \"bar\". Но если мы изменим значение foo в дочернем процессе, это никак не повлияет на переменную foo, которая была объявлена в родительском процессе.\n",
    "\n",
    "Итак, мы узнали, что память в дочерний процесс копируется, и что дочерний и родительский процессы пользуются разной памятью.\n",
    "\n",
    "То же самое относится и к файловым дискрипторам. Предположим, у нас есть небольшой файл с двумя строчками: example string1 и example string2. Открываем файл на чтение и читаем в переменную foo одну строчку. После того, как мы считали одну строчку, делаем системный вызов fork. После этого у нас создается точная копия родительского процесса:\n",
    "\n",
    "```python\n",
    "# ex4.py\n",
    "\n",
    "# cat data.txt\n",
    "# example string1\n",
    "# example string2\n",
    "\n",
    "import os\n",
    "\n",
    "f = open(\"data.txt\")\n",
    "foo = f.readline()\n",
    "\n",
    "if os.fork() == 0:\n",
    "    # дочерний процесс\n",
    "    foo = f.readline()\n",
    "    print(\"child:\", foo)\n",
    "else:\n",
    "    # родительский процесс\n",
    "    foo = f.readline()\n",
    "    print(\"parent:\", foo)\n",
    "```\n",
    "\n",
    "```bash\n",
    "python ex4.py\n",
    "```\n",
    "\n",
    "Если мы в дочернем процессе снова вызовем метод readline() у объекта f, то мы прочитаем уже вторую строчку из этого файла. Но это никак не повлияет на родительский процесс. В родительском процессе, если мы вызовем readline(), то мы точно так же считаем вторую строчку:\n",
    "\n",
    "Итак, ещё раз обращаем внимание, что не только память, но и файловые дискрипторы целиком и полностью копируются в дочернем процессе, когда мы делаем системный вызов fork.\n",
    "\n",
    "Все эти примеры носят обучающий характер, и обычно код с использованием системных вызовов fork немного сложнее. fork может вернуть ошибку, которую нужно проверять, поэтому обычно в Python-е для создания процессов используют модуль multiprocessing. Для того, чтобы запустить процесс таким способом, необходимо импортировать класс Process из модуля multiprocessing, создать объект класса Process, передать ему в конструктор функцию, которую мы хотим исполнить в отдельном дочернем процессе и аргументы этой функции. Процесс будет создан тогда, когда мы вызовем метод start нашего объекта. Внутри метода start будет вызван системный вызов fork и исполнена наша функция f в отдельном процессе. Очень важно ожидать завершения всех созданных дочерних процессов. Для этого можно воспользоваться удобной функцией join:\n",
    "\n",
    "```python\n",
    "# ex5.py \n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "def f(name):\n",
    "    print(\"hello\", name)\n",
    "\n",
    "p = Process(target=f, args=(\"Bob\",))\n",
    "p.start()\n",
    "p.join()\n",
    "```\n",
    "\n",
    "```bash\n",
    "python ex5.py\n",
    "```\n",
    "\n",
    "Как мы видим, системные вызовы fork и wait спрятаны внутри красивых оберток.\n",
    "\n",
    "Вообще, не в каждой операционной системе есть системный вызов fork, и поэтому в multiprocessing все аккуратно сделано за вас.\n",
    "\n",
    "Существует также альтернативный метод создания процесса при помощи\n",
    "multiprocessing — используя механизм наследования. Для этого мы объявляем свой класс, наследуемся от класса Process. В конструктор передаем нужные параметры для функции, которая должна быть запущена в дочернем процессе и переопределяем метод run. В методе run мы реализуем код, который должен выполнять дочерний прочесс. Далее создаем объект нашего класса PrintProcess, передаем туда параметры, вызываем метод start. Метод start вызовет fork и выполнит наш код в дочернем процессе. Для завершения дочернего процесса мы вызываем метод join:\n",
    "\n",
    "```python\n",
    "# ex6.py\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "class PrintProcess(Process):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        print(\"hello\", self.name)\n",
    "\n",
    "p = PrintProcess(\"Mike\")\n",
    "p.start()\n",
    "p.join()\n",
    "```\n",
    "\n",
    "```bash\n",
    "python3 ex6.py\n",
    "```\n",
    "\n",
    "Очень важно ожидать завершения всех дочерних процессов, чтобы контролировать освобождение всех ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "5.2.3. Создание потоков\n",
    "В этом разделе мы поговорим о потоках. Мы обсудим создание потоков при помощи модуля threading и использование класса ThreadPoolExecutor. С прикладной точки зрения поток целиком и полностью напоминает процесс. Он имеет свою последовательность\n",
    "инструкций для исполнения, у каждого потока есть свой собственный стек, но все потоки\n",
    "выполняются в рамках одного процесса. Этим они отличаются от процессов. Если, когда\n",
    "мы говорили о процессах, у каждого процесса были свои ресурсы и память, то все созданные потоки разделяют память процесса и все его ресурсы. Управлением и выполнением\n",
    "потоков занимается операционная система. Но в Python есть свои ограничения для потоков — их мы обсудим отдельно.\n",
    "Итак, давайте рассмотрим пример создания потока на Python. Всё будет очень похоже на создание процессов. Во-первых, используем модуль threading и импортируем из\n",
    "него класс Thread. Далее мы объявляем функцию, которую хотим исполнить в отдельном\n",
    "потоке и создаем объект класса Thread, передав в него нашу функцию f и аргументы, с\n",
    "которыми эта функция должна быть вызвана. После того как мы создали объект, никакого\n",
    "потока запущено не будет — он будет запущен, когда мы вызовем метод start у этого\n",
    "объекта. Также очень важно дожидаться выполнения завершения всех созданных потоков при помощи метода join:\n",
    "# Создание потока\n",
    "from threading import Thread\n",
    "def f(name):\n",
    "print(\"hello\", name)\n",
    "th = Thread(target=f, args=(\"Bob\",))\n",
    "th.start()\n",
    "th.join()\n",
    "hello Bob\n",
    "Существует также альтернативный метод создания потока при помощи наследования.\n",
    "Опять же, всё очень похоже на использование модуля multiprocessing. Мы объявляем\n",
    "свой класс, наследуемый от класса Thread и в конструктор передаем нужные аргументы,\n",
    "чтобы выполнить функцию в отдельном потоке:\n",
    "10\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Создание потока\n",
    "from threading import Thread\n",
    "class PrintThread(Thread):\n",
    "def __init__(self, name):\n",
    "super().__init__()\n",
    "self.name = name\n",
    "def run(self):\n",
    "print(\"hello\", self.name)\n",
    "th = PrintThread(\"Mike\")\n",
    "th.start()\n",
    "th.join()\n",
    "hello Mike\n",
    "В Python3 появился очень удобный класс для создания пула потоков —\n",
    "ThreadPoolExecutor из модуля concurrent.futures. Предположим, у нас есть некий\n",
    "массив чисел, и нам нужно с помощью ограниченного количества потоков рассчитать квадраты этих чисел. Для этого можно использовать контекстный менеджер, указать в нем\n",
    "вызов ThreadPoolExecutor с параметром max_workers, который как раз отвечает за\n",
    "максимальное количество потоков, которые будут созданы в этом блоке with. Нужное\n",
    "количество потоков будет создано автоматически, и при завершении контекстного менеджера будет вызвана функция shutdown, которая дождется завершения всех созданных\n",
    "потоков. Основная функция у ThreadPoolExecutor — это метод submit. Он создает\n",
    "объект класса\n",
    "concurrent.futures.Future — это такой объект, который еще не завершился, но выполняется и будет завершен в будущем. При помощи удобного метода as_completed из\n",
    "модуля concurrent.futures мы можем дождаться завершения всех объектов и получить результаты по мере завершения всех созданных нами потоков:\n",
    "# Пул потоков, concurrent.futures.Future\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def f(a):\n",
    "return a * a\n",
    "# .shutdown() in exit\n",
    "with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "results = [pool.submit(f, i) for i in range(10)]\n",
    "for future in as_completed(results):\n",
    "print(future.result())\n",
    "11\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "0\n",
    "1\n",
    "4\n",
    "9\n",
    "...\n",
    "5.2.4. Синхронизация потоков\n",
    "В этом видео мы поговорим про синхронизацию потоков и обсудим очереди, блокировки\n",
    "и условные переменные. Если вы запустите несколько потоков для решения своей задачи, то вам рано или поздно придётся обмениваться данными между потоками. Часто для\n",
    "синхронизации потоков используют блокировки. Но любые блокировки замедляют выполнение программы. Лучше не использовать блокировки и отдавать предпочтение обмену\n",
    "данными через очереди.\n",
    "Давайте для начала разберёмся, как можно использовать модуль queue и очереди для\n",
    "обмена данными между потоками. Использование очередей выглядит достаточно простым. В следующем примере мы создаём объект типа очередь с максимальным размером 5. Для помещения элементов в очередь необходимо использовать метод put объекта Queue. Обращаем ваше внимание, что если в очереди будет уже пять элементов, то\n",
    "вызов метода put заблокирует выполнение потока, который вызвал этот метод, и будет\n",
    "ждать, пока в очереди не появится свободное место. Итак, для обработки сообщений этой\n",
    "очереди мы создаём пару потоков — объектов класса Thread. Передаём в этот объект\n",
    "функцию worker, которой передаём нашу очередь. Итак, функция worker будет выполняться в двух независимых параллельных потоках. Каждый поток в бесконечном цикле\n",
    "будет получать сообщение из очереди при помощи вызова метода get у объекта q:\n",
    "12\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Очереди, модуль queue\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "def worker(q, n):\n",
    "while True:\n",
    "item = q.get()\n",
    "if item is None:\n",
    "break\n",
    "print(\"process data:\", n, item)\n",
    "q = Queue(5)\n",
    "th1 = Thread(target=worker, args=(q, 1))\n",
    "th2 = Thread(target=worker, args=(q, 2))\n",
    "th1.start(); th2.start()\n",
    "for i in range(50):\n",
    "q.put(i)\n",
    "q.put(None); q.put(None)\n",
    "th1.join(); th2.join()\n",
    "process data: 1 0\n",
    "process data: 1 1\n",
    "process data: 2 3\n",
    "...\n",
    "Большое внимание нужно уделить правильному завершению потока. Ресурсами процесса, то есть выделенной памятью или открытым файлом владеет сам процесс. Но процесс ничего не знает о том, что делает с этими ресурсами поток. И если поток завершить\n",
    "аварийно, то файл может остаться незакрытым, блокировка — невысвобожденной, что\n",
    "теоретически может привести к непредвиденным последствиям. Поэтому в Python не существует функции аварийного завершения потока. Очень важно делать это правильно в\n",
    "функции самого потока. На приведённом выше примере в очередь помещается специальное значение None, и функция потока при проверке условия завершает свою работу.\n",
    "Использование очередей делает код выполняемой программы более простым. И, по\n",
    "возможности, лучше разрабатывать код таким образом, чтобы не было глобального разделяемого ресурса или состояния. Тем не менее, иногда приходится использовать блокировки.\n",
    "Давайте рассмотрим пример. Предположим, у нас есть класс Point, и у класса Point\n",
    "есть координаты x и y. Также у этого класса есть метод get, который возвращает координаты, и метод set, который задаёт новые координаты. Предположим, что мы создали\n",
    "объект класса Point и используем этот объект в большом количестве потоков. Некоторые\n",
    "потоки вызывают метод get, другие вызывают метод set. Если бы не было блокировок,\n",
    "то могла возникнуть ситуация, когда один поток изменил значение координаты x, а другой поток в это время вернул координаты x и y. Мы получили неконсистентное состояние\n",
    "13\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "объекта, у которого одна координата изменена, а вторая нет.\n",
    "# Синхронизация потоков, race condition\n",
    "import threading\n",
    "class Point(object):\n",
    "def __init__(self, x, y):\n",
    "self.set(x, y)\n",
    "def get(self):\n",
    "return (self.x, self.y)\n",
    "def set(self, x, y):\n",
    "self.x = x\n",
    "self.y = y\n",
    "# use in threads\n",
    "my_point = Point(10, 20)\n",
    "my_point.set(15, 10)\n",
    "my_point.get()\n",
    "Чтобы избежать подобных ситуаций, нужны блокировки. Для создания блокировки используют метод threading.RLock(). Создаём объект блокировки, и теперь при входе в\n",
    "контекстный менеджер мы захватываем блокировку, а при выходе блокировка высвобождается:\n",
    "14\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Синхронизация потоков, блокировки\n",
    "import threading\n",
    "class Point(object):\n",
    "def __init__(self, x, y):\n",
    "self.mutex = threading.RLock()\n",
    "self.set(x, y)\n",
    "def get(self):\n",
    "with self.mutex:\n",
    "return (self.x, self.y)\n",
    "def set(self, x, y):\n",
    "with self.mutex:\n",
    "self.x = x\n",
    "self.y = y\n",
    "# use in threads\n",
    "my_point = Point(10, 20)\n",
    "my_point.set(15, 10)\n",
    "my_point.get()\n",
    "Таким образом можно легко и удобно создавать блокировки на Python. Подобные ситуации иногда называют гонкой за ресурсами, или race condition.\n",
    "Давайте рассмотрим ещё один вариант применения блокировок. Их можно использовать без контекстного менеджера. На примере мы создаём объекты класса RLock и затем\n",
    "вызываем методы acquire, чтобы получить или захватить блокировку, и метод release\n",
    "для того, чтобы высвободить её:\n",
    "# Синхронизация потоков, блокировки\n",
    "import threading\n",
    "a = threading.RLock()\n",
    "b = threading.RLock()\n",
    "def foo():\n",
    "try:\n",
    "a.acquire()\n",
    "b.acquire()\n",
    "finally:\n",
    "a.release()\n",
    "b.release()\n",
    "15\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Если мы запустим подобный код в большом количестве процессов, то рано или поздно\n",
    "это приведёт к ситуации, которая называется deadlock. Дело в том, что мы освобождаем\n",
    "блокировки в неправильной последовательности. Нужно учитывать это в своих программах и отдавать предпочтение использованию контекстного менеджера при работе с блокировками. Также в Python существует ещё и объект класса Lock, а не RLock, но предпочтительнее использовать объекты RLock — они позволяют в одном потоке получить\n",
    "блокировку дважды.\n",
    "В Python существует ещё один механизм для синхронизации потоков — он называется\n",
    "условные переменные. Давайте рассмотрим класс Queue. Это очередь, с которой нужно\n",
    "будет работать в большом количестве потоков. У неё есть операции put и get, и, конечно же, у неё есть размер. Если мы выполним операцию put, а в очереди уже достаточно\n",
    "большое количество элементов, то нам необходимо ждать пока это количество уменьшится. Вопрос — сколько ждать? Неизвестно. Для решения подобной задачи можно использовать условные переменные. Условная переменная threading.Condition получает в\n",
    "конструктор объект блокировки self._mutex (он есть по умолчанию, но если условные\n",
    "переменные взаимозависимые, то необходимо использовать общую блокировку). И при\n",
    "помощи этих условных переменных легко и удобно ожидать событий при помощи вызова\n",
    "wait и оповещать все потоки, которые сейчас ждут наступления этого события с помощью функции notify:\n",
    "# Синхронизация потоков, условные переменные\n",
    "class Queue(object):\n",
    "def __init__(self, size=5):\n",
    "self._size = size\n",
    "self._queue = []\n",
    "self._mutex = threading.RLock()\n",
    "self._empty = threading.Condition(self._mutex)\n",
    "self._full = threading.Condition(self._mutex)\n",
    "def put(self, val):\n",
    "with self._full:\n",
    "while len(self._queue) >= self._size:\n",
    "self._full.wait()\n",
    "self._queue.append(val)\n",
    "self._empty.notify()\n",
    "def get(self):\n",
    "with self._empty:\n",
    "while len(self._queue) == 0:\n",
    "self._empty.wait()\n",
    "ret = self._queue.pop(0)\n",
    "self._full.notify()\n",
    "return ret\n",
    "16\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Таким образом можно реализовать очередь в Python, которая работает в многопоточной программе.\n",
    "Все механизмы блокировки и обмена данными между потоками имеют место и для\n",
    "процессов, но вместо модуля threading нужно использовать multiprocessing.\n",
    "5.2.5. Глобальная блокировка интерпретатора\n",
    "Поговорим о том, что такое глобальная блокировка интерпретатора, или, как её сокращенно называют, GIL. GIL очень тесно связан с выполнением потоков. Многие разработчики знают о GIL лишь то, что это какая-то штука, которая не позволяет одновременно\n",
    "двум потокам выполняться на одном ядре процессора, даже если этих ядер у процессора несколько. Тем не менее, GIL в первую очередь предназначен для защиты памяти\n",
    "интерпретатора от разрушений и делает все операции с памятью атомарными. Давайте\n",
    "рассмотрим следующую программу:\n",
    "# cpu bound programm\n",
    "from threading import Thread\n",
    "import time\n",
    "def count(n):\n",
    "while n > 0:\n",
    "n -= 1\n",
    "# series run\n",
    "t0 = time.time()\n",
    "count(100_000_000)\n",
    "count(100_000_000)\n",
    "print(time.time() - t0)\n",
    "# parallel run\n",
    "t0 = time.time()\n",
    "th1 = Thread(target=count, args=(100_000_000,))\n",
    "th2 = Thread(target=count, args=(100_000_000,))\n",
    "th1.start(); th2.start()\n",
    "th1.join(); th2.join()\n",
    "print(time.time() - t0)\n",
    "Можем посмотреть при помощи команды top, что этот пример потребляет почти 100%\n",
    "CPU на одном ядре. Давайте вернемся к программе и рассмотрим, что она делает. Прежде всего, у нас есть функция count, которая в цикле уменьшает значение счетчика до\n",
    "нуля. Нам необходимо выполнить два вызова этой функции со значением 100_000_000\n",
    "и засечь, сколько времени займет выполнение двух функций с этим счетчиком. Функция\n",
    "потребляет только центральный процессор и не делает никаких операций ввода-вывода,\n",
    "17\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "не ходит в сеть. Для сравнения мы выполним эту функцию в потоке. Создадим два потока\n",
    "при помощи уже известных нам ранее методов модуля threading. Передадим туда эту\n",
    "функцию, те же самые аргументы, запустим наши потоки, подождем, пока они завершатся при помощи метода join, и выведем количество секунд, которое было потрачено на\n",
    "выполнение работы этих двух потоков:\n",
    "15.281397104263306\n",
    "15.86177659034729\n",
    "Видим, что параллельное выполнение при помощи потоков заняло больше времени.\n",
    "Как же так? Тогда зачем нужны потоки, и почему так происходит? Всё дело в глобальной\n",
    "блокировке интерпретатора.\n",
    "Дело в том, что потоки при выполнении своего кода каждый раз получают блокировку\n",
    "интерпретатора. Если у нас задача CPU-bound (так называют задачи, которые потребляют только ресурсы процессора), то код, написанный с использованием тредов в Python,\n",
    "будет неэффективным. Он будет работать медленнее, чем код, который запущен последовательно. Тем не менее, если мы код нашей функции заменим, например, на задачу,\n",
    "которая требует операции ввода-вывода, то мы заметим большой прирост в итоговом времени выполнения, если сравнивать последовательное выполнение и выполнение в тредах.\n",
    "Схематично изобразим процесс выполнения потока. Есть поток, в котором выполняется Python-код, и каждый раз Python-интерпретатор пробует получить глобальную блокировку интерпретатора. Если Python выполняет операцию ввода-вывода или системный\n",
    "вызов, он снимает блокировку, и далее выполнение происходит без блокировки. Поэтому\n",
    "если таких будет потоков много, все задачи с вводом-выводом, с ожиданием завершения\n",
    "для операций ввода-вывода будут очень хорошо параллелиться:\n",
    "# как выполняется поток?\n",
    "a r a r a r a\n",
    "run |------| run |--------------| run |----| run\n",
    "------>| IO |----------->| IO |--------->| IO |----->\n",
    "|------| |--------------| |----|\n",
    "a r a r a r a\n",
    "a - acquire GIL\n",
    "r - release GIL\n",
    "Это нужно учитывать в задачах, в которых вы будете применять потоки или процессы. GIL реализован внутри как обычная нерекурсивная блокировка или объект класса\n",
    "threading.Lock. Все потоки спят пять миллисекунд в ожидании получения блокировки, и если работает один главный поток, то он не требует освобождения этой глобальной\n",
    "блокировки интерпретатора. Итак, в этом видео мы обсудили, что такое GIL и какое отношение он имеет к потокам в Python. Так, Python-потоки — это обычные потоки, или POSIX\n",
    "threads, но с ограничениями в виде глобальной блокировки интерпретатора. Все потоки\n",
    "18\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "выполняются с захватом GIL, но для системных вызовов и операций ввода-вывода GIL\n",
    "не нужен. Итак, мы рассмотрели вопросы про то, как работают потоки и процессы, и в\n",
    "следующих разделах мы рассмотрим, как устроены сокеты и как работать с сетью с применением полученных знаний о потоках и процессах.\n",
    "5.3. Работа с сетью, сокеты\n",
    "5.3.1. Сокеты, клиент-сервер\n",
    "В следующих разделах мы будем изучать то, как устроены сокеты и как работают сетевые\n",
    "программы. Сокеты — это кросс-платформенный механизм для обмена данными между\n",
    "отдельными процессами. Эти процессы могут работать на разных серверах, они могут\n",
    "быть написаны на разных языках, и, прежде всего, программа на Python, которая использует механизм сокетов, осуществляет системные вызовы и взаимодействие с ядром операционной системы. Как правило, для организации сетевого взаимодействия нужен сервер, который изначально создает некое соединение и начинает «слушать» все запросы,\n",
    "которые поступают в него, и программа-клиент, которая присоединяется к серверу и отправляет ему нужные данные.\n",
    "Давайте рассмотрим пример серверной программы. Чтобы создать сокет, мы должны\n",
    "импортировать модуль socket. Далее мы должны создать объект типа socket из модуля\n",
    "socket. В него необходимо передать некоторые параметры. В данном случае это некоторое семейство address family AF_INET, а также тип сокета (потоковый сокет). (Полную\n",
    "информацию по типам сокетов и по типам address family можно посмотреть в документации Python, либо в документации про то, как устроена сеть в операционной системе\n",
    "Linux.) Итак, мы создали объект socket. Далее мы должны вызвать метод bind. В метод\n",
    "bind мы должны передать некую адресную пару — это хост и порт. В качестве хоста в\n",
    "данном случае мы передаем 127.0.0.1 — наш сервер будет слушать все входящие соединения только локально на одной машине. Если мы укажем пустую строчку, либо адрес\n",
    "0.0.0.0, то наш сервер будет слушать входящие соединения со всех интерфейсов. Порт\n",
    "— это некая целочисленная константа, существуют некоторые зарезервированные порты, например, 80-й порт (обычно на нем работает HTTP-сервер), 43-й порт, 443-й порт.\n",
    "Как правило, порты с номерами до 2000 являются системными, и мы должны использовать адреса больше значений 2000, но максимальное значение для порта — это 65535.\n",
    "Итак, системный вызов bind зарегистрировал нашу адресную пару в операционной\n",
    "системе. Далее, для того чтобы начать принимать соединения, мы должны вызвать метод\n",
    "listen. У метода listen есть необязательный параметр — это так называемый backlog,\n",
    "или размер очереди входящих соединений, которые еще не обработаны, для которых не\n",
    "был вызван метод accept. Если наш сервер будет не успевать принимать входящие соединения, то все эти соединения будут копиться в backlog, и если он превысит максимальное значение, то операционная система выдаст ошибку ConnectionRefused для\n",
    "клиентской программы. Далее мы должны вызвать метод accept, чтобы начать принимать входящее клиентское соединение. Системный вызов accept по умолчанию заблокируется, до тех пор, пока не появится клиентское соединение. Итак, если клиент вызовет\n",
    "19\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "метод connect, то наш метод accept вернет нам объект, который будет являться полнодуплексным каналом. У этого объекта будут доступны методы записи в этот канал и методы чтения. В нашем примере мы в бесконечном цикле будем вызывать чтение из нашего\n",
    "полнодуплексного канала. Если мы ничего не прочитали, это будет означать, что клиент\n",
    "закрыл соединение и серверу тоже необходимо прекратить работу. Данные, которые мы\n",
    "прочитали с канала, мы выводим в консоль. После того как мы закончили работу с нашим\n",
    "клиентом, мы вызываем метод close для нашего объекта, который представляет собой\n",
    "полнодуплексный канал, а также закрываем сокет, который слушает новые соединения со\n",
    "стороны клиента:\n",
    "# создание сокета, сервер\n",
    "import socket\n",
    "# https://docs.python.org/3/library/socket.html\n",
    "sock=socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "sock.bind((\"127.0.0.1\", 10001)) # max port 65535\n",
    "sock.listen(socket.SOMAXCONN)\n",
    "conn, addr = sock.accept()\n",
    "while True:\n",
    "data = conn.recv(1024)\n",
    "if not data:\n",
    "break\n",
    "# process data\n",
    "print(data.decode(\"utf8\"))\n",
    "conn.close()\n",
    "sock.close()\n",
    "Давайте рассмотрим код на стороне клиента. Чтобы установить соединение с сервером, мы должны создать объект типа socket.socket. По умолчанию создается потоковый сокет с семейством address family AF_INET. После этого мы должны вызвать метод\n",
    "connect. Connect заблокируется до тех пор, пока сервер со своей стороны не вызовет\n",
    "метод accept. После того как системный вызов connect отработал, наш сокет готов к\n",
    "работе, и для него можно вызывать методы send, sendall или recv, чтобы получать\n",
    "данные с сервера. После того как мы завершили работу с нашим клиентским сокетом,\n",
    "необходимо вызвать метод close:\n",
    "# создание сокета, клиент\n",
    "import socket\n",
    "sock = socket.socket()\n",
    "sock.connect((\"127.0.0.1\", 10001))\n",
    "sock.sendall(\"ping\".encode(\"utf8\"))\n",
    "sock.close()\n",
    "20\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "В Python существует более короткая запись для создания клиентского сокета — это вызов метода модуля socket create_connection. В create_connection мы передаем\n",
    "адресную пару и необязательный timeout (про который мы ещё будем говорить в следующих разделах). Этот вызов возвращает нам соединение, готовое для того, чтобы делать\n",
    "отправку или прием данных.\n",
    "# создание сокета, клиент\n",
    "# более короткая запись\n",
    "sock = socket.create_connection((\"127.0.0.1\", 10001))\n",
    "sock.sendall(\"ping\".encode(\"utf8\"))\n",
    "sock.close()\n",
    "Теперь мы можем запустить сервер и затем клиент, который отправит серверу байтовую строку \"ping\" (обращаем ваше внимание, что при работе с данными по сети мы\n",
    "вынуждены отправлять именно байты, а не строки).\n",
    "Как мы уже говорили, socket — это кроссплатформенный механизм и необязательно\n",
    "программа-клиент и сервер должны быть написаны на одном и том же языке. Наш пример\n",
    "будет работать и в том случае, если мы воспользуемся вместо клиента программой telnet.\n",
    "Соединения и сокеты необходимо корректно закрывать. Поэтому в Python существует\n",
    "более удобный механизм для работы с сокетами в виде контекстных менеджеров. Давайте рассмотрим пример, в котором мы выполняем те же самые задачи, но используем контекстный менеджер. Итак, мы используем на стороне сервера конструкцию with\n",
    "socket.socket, создаём наш объект типа socket, вызываем методы bind, listen. Затем в бесконечном цикле вызываем accept и получаем новые соединения от клиентов.\n",
    "Для полученного объекта мы опять используем контекстный менеджер и мы не заботимся\n",
    "о вызовах метода close:\n",
    "# создание сокета, контекстный менеджер\n",
    "# сервер\n",
    "import socket\n",
    "with socket.socket() as sock:\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "while True:\n",
    "conn, addr = sock.accept()\n",
    "with conn:\n",
    "while True:\n",
    "data = conn.recv(1024)\n",
    "if not data:\n",
    "break\n",
    "print(data.decode(\"utf8\"))\n",
    "21\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "После того как контекстный менеджер завершит свою работу, он автоматически вызовет метод close для нужных нам объектов. Это очень удобно, и это позволяет допускать\n",
    "вам меньшее количество ошибок при работе с сокетами. На стороне клиента мы снова\n",
    "используем контекстный менеджер для вызова socket.create.connection:\n",
    "# клиент\n",
    "import socket\n",
    "with socket.create_connection((\"127.0.0.1\", 10001)) as sock:\n",
    "sock.sendall(\"ping\".encode(\"utf8\"))\n",
    "Предпочтительнее работать с контекстными менеджерами при написании клиентсерверных программ на языке Python.\n",
    "5.3.2. Таймауты и обработка сетевых ошибок\n",
    "Сеть не всегда может работать стабильно, поэтому в сетевых программах необходимо\n",
    "обрабатывать различные ошибки. Давайте рассмотрим обучающий пример с обработкой\n",
    "ошибок. Рассмотрим немного изменённый код сервера из предыдущего раздела. Здесь\n",
    "после того, как мы получили соединение с помощью команды sock.accept(), мы устанавливаем timeout командой settimeout. Значение таймаута по умолчанию — это None,\n",
    "а значение 0 переведёт сокет в неблокирующий режим, про который мы будем говорить\n",
    "позднее. Мы установили таймаут, равный 5 секундам:\n",
    "# создание сокета, таймауты и обработка ошибок\n",
    "# сервер\n",
    "import socket\n",
    "with socket.socket() as sock:\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "while True:\n",
    "conn, addr = sock.accept()\n",
    "conn.settimeout(5) # timeout := None|0|gt 0\n",
    "with conn:\n",
    "while True:\n",
    "try:\n",
    "data = conn.recv(1024)\n",
    "except socket.timeout:\n",
    "print(\"close connection by timeout\")\n",
    "break\n",
    "if not data:\n",
    "break\n",
    "print(data.decode(\"utf8\"))\n",
    "22\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Теперь, если после вызова recv нам не поступит данных в течение 5 секунд, будет\n",
    "сгенерировано исключение socket.timeout. Затем мы закрываем соединение.\n",
    "Рассмотрим код на клиенте. На клиенте существует connect timeout и socket read timeout.\n",
    "Connect timeout мы задаём в методе create_connection, он будет распространяться\n",
    "только на установку соединения с нашим сервером. После того, как соединение будет\n",
    "установлено, мы можем задать socket read timeout на все операции с нашим сокетом:\n",
    "# создание сокета, таймауты и обработка ошибок\n",
    "# клиент\n",
    "import socket\n",
    "with socket.create_connection((\"127.0.0.1\", 10001), 5) as sock:\n",
    "# set socket read timeout\n",
    "sock.settimeout(2)\n",
    "try:\n",
    "sock.sendall(\"ping\".encode(\"utf8\"))\n",
    "except socket.timeout:\n",
    "print(\"send data timeout\")\n",
    "except socket.error as ex:\n",
    "print(\"send data error:\", ex)\n",
    "Также могут возникнуть другие исключения, которые тоже нужно обрабатывать. Базовый класс для этих исключений — это socket.error.\n",
    "5.3.3. Обработка нескольких соединений\n",
    "Итак, в предыдущих разделах мы рассматривали простые программы типа клиент-сервер\n",
    "и пробовали организовать взаимодействие между двумя процессами. А что делать, если\n",
    "этих процессов будет несколько или не несколько, а очень много? Если мы приняли соединение и начинаем его обработку в том же самом потоке управления, мы не можем принимать новые соединения. Если у нас будет большое количество клиентов, то все остальные\n",
    "клиенты будут вынуждены ждать, пока мы закончим работу с первым соединением. Какие\n",
    "подходы существуют для решения данной задачи?\n",
    "Конечно, мы можем создать процесс или поток для обработки отдельного соединения\n",
    "и выполнить в этом процессе или потоке код по его обработке. Если мы создадим 10,000\n",
    "процессов, это будет иметь ряд своих минусов. Как минимум, это потребует очень больших ресурсов от нашей операционной системы, а также само создание процесса является \"дорогой\" операцией. Тем не менее, такой подход иногда используется, и, если у вас\n",
    "небольшое количество соединений, плюсом будет то, что вы можете использовать все ядра операционной системы и распределять обработку по всем ядрам на сервере.\n",
    "Если же мы будем обрабатывать новые соединения в потоках, то, как мы помним, все\n",
    "потоки работают в Python на одном ядре, и они ограничены GIL. Рано или поздно мы\n",
    "упремся в то, что нам не хватает одного ядра, и наш сервер будет отвечать медленно.\n",
    "23\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Тем не менее, и на потоках, особенно если они требуют операции ввода-вывода, можно\n",
    "получить достаточно производительный сервер.\n",
    "Давайте рассмотрим пример одновременной обработки сетевых запросов при помощи\n",
    "потоков. Итак, мы создаем socket, вызываем нами известные методы bind и listen.\n",
    "Затем в бесконечном цикле принимаем входящее соединение от клиента. Как только мы\n",
    "приняли это входящее соединение, мы должны создать поток. Делаем это мы при помощи\n",
    "модуля threading, создаем объект класса Thread, передаём ему в качестве аргумента\n",
    "функцию и наше соединение, с которым будем дальше в этой функции работать. Запускаем поток, а в основном потоке продолжаем акцептить новые соединения:\n",
    "# обработка нескольких соединений одновременно, потоки\n",
    "import socket\n",
    "import threading\n",
    "def process_request(conn, addr):\n",
    "print(\"connected client:\", addr)\n",
    "with conn:\n",
    "while True:\n",
    "data = conn.recv(1024)\n",
    "if not data:\n",
    "break\n",
    "print(data.decode(\"utf8\"))\n",
    "with socket.socket() as sock:\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "while True:\n",
    "conn, addr = sock.accept()\n",
    "th = threading.Thread(target=process_request,\n",
    "args=(conn, addr))\n",
    "th.start()\n",
    "Если процесс обработки этих соединений будет заниматься вводом-выводом, то такой\n",
    "код будет достаточно производительным. Тем не менее, если будет недостаточно одного ядра операционной системы, можно этот процесс распараллелить. Давайте рассмотрим пример, когда можно использовать и потоки, и процессы одновременно. Итак, для того чтобы обрабатывать одно соединение в нескольких процессах, нам нужно выполнить\n",
    "небольшой трюк. После того как мы вызвали метод listen, мы должны создать несколько\n",
    "процессов, сделать fork. После того как мы сделаем вызов fork, все ресурсы родительского процесса будут целиком и полностью скопированы в дочерние процессы, тем самым\n",
    "в наших дочерних процессах будет тот же самый socket. Если мы в этом socket-е сделаем вызов accept и будем ждать нового соединения от клиента, то системный вызов\n",
    "accept распределит равномерно между всеми дочерними процессами новые входящие\n",
    "соединения, а уже дальше в этих дочерних процессах, когда мы поймали новые соединения, мы уже сможем создать поток и обработать новые соединения. Опишем эту схему\n",
    "24\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "комментариями в коде:\n",
    "# обработка нескольких соединений одновременно, процессы и потоки\n",
    "import socket\n",
    "with socket.socket() as sock:\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "# создание нескольких процессов\n",
    "while True:\n",
    "# accept распределится \"равномерно\" между процессами\n",
    "conn, addr = sock.accept()\n",
    "# поток для обработки соединения\n",
    "with conn:\n",
    "while True:\n",
    "data = conn.recv(1024)\n",
    "if not data:\n",
    "break\n",
    "print(data.decode(\"utf8\"))\n",
    "Если, опять же, мы создадим несколько процессов, которые все одновременно делают\n",
    "системный вызов accept, то по умолчанию все они будут спать, а операционная система\n",
    "не будет потреблять никаких ресурсов. Но если будет приходить новое входящее соединение, операционная система разбудит все наши процессы. В этом месте есть небольшой\n",
    "overhead, нужно это понимать.\n",
    "Вот так может выглядеть код нашего сервера на процессах:\n",
    "25\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# обработка нескольких соединений одновременно, процессы и потоки\n",
    "import socket\n",
    "import threading\n",
    "import multiprocessing\n",
    "with socket.socket() as sock:\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "workers_count = 3\n",
    "workers_list = [multiprocessing.Process(target=worker,\n",
    "args=(sock,))\n",
    "for _ in range(workers_count)]\n",
    "for w in workers_list:\n",
    "w.start()\n",
    "for w in workers_list:\n",
    "w.join()\n",
    "Как обычно, мы создаем socket, вызываем методы bind и listen. Затем мы должны\n",
    "при помощи модуля multiprocessing создать несколько объектов worker, которые будут обрабатывать новые соединения.\n",
    "Давайте рассмотрим код наших worker-ов. Итак, каждый worker, который будет запущен в отдельном процессе, делает системный вызов accept. Все входящие соединения\n",
    "будут равномерно распределены между worker-ами при помощи операционной системы.\n",
    "И после того как соединение попало в наш процесс, необходимо создать поток и передать\n",
    "ему метод process_request, который обрабатывает данное соединение:\n",
    "26\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# обработка нескольких соединений одновременно, процессы и потоки\n",
    "def worker(sock):\n",
    "while True:\n",
    "conn, addr = sock.accept()\n",
    "print(\"pid\", os.getpid())\n",
    "th = threading.Thread(target=process_request,\n",
    "args=(conn, addr))\n",
    "th.start()\n",
    "def process_request(conn, addr):\n",
    "print(\"connected client:\", addr)\n",
    "with conn:\n",
    "while True:\n",
    "data = conn.recv(1024)\n",
    "if not data:\n",
    "break\n",
    "print(data.decode(\"utf8\"))\n",
    "Таким образом, используя одновременно процессы и потоки, мы сможем решить проблему с GIL и проблему с памятью.\n",
    "5.4. Асинхронное программирование\n",
    "5.4.1. Исполнение кода в одном потоке, модуль select\n",
    "В операционной системе существует модуль select, который позволяет организовать\n",
    "работу с неблокирующим вводом-выводом. Отдельно хочется сказать, что существует\n",
    "несколько механизмов опроса всех файловых дескрипторов для организации неблокирующего ввода-вывода: select.select, select.poll, select.epoll и select.kqueue.\n",
    "Все эти методы связаны с особенностями операционных систем. Например, в Linux, как\n",
    "правило, используют epoll, и мы будем рассматривать примеры на основе epoll.\n",
    "Вспомним, что у нас была проблема создания сокета и обработки нескольких входящих\n",
    "соединений одновременно. Давайте попробуем сделать это при помощи модуля select.\n",
    "Итак, предположим, мы создали объект класс socket, вызвали метод bind, вызвали метод listen и смогли вызвать метод accept для двух соединений. Теперь у нас есть два\n",
    "объекта соединения — conn1 и conn2, и нам необходимо одновременно читать или записывать данные из этих соединений без использования потоков или процессов. Для этого\n",
    "необходимо перевести наше соединение, во-первых, в неблокирующий режим при помощи вызова setblocking(0) (равносильно тому, что мы сделаем вызов settimeout(0)).\n",
    "Теперь наши сокеты в неблокирующем режиме, и если мы попробуем что-то прочитать\n",
    "из этого сокета, а там данных нет, то наш вызов recv не заблокируется, а вернет некую\n",
    "системную ошибку. Но как узнать, какие сокеты готовы читать, а какие сокеты готовы записывать данные? Для этого как раз нам понадобится объект epoll. Мы регистрируем в\n",
    "27\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "объекте epoll наши файловые дескрипторы от созданных коннектов, а также говорим,\n",
    "на какие события подписываемся от этих файловых дескрипторов. В данном случае это\n",
    "чтение из сокетов и запись в сокет (select.EPOLLIN | select.EPOLLOUT). Далее для\n",
    "организации цикла опроса событий нам необходимо запомнить наши объекты и смапить\n",
    "их по файловым дескрипторам. То есть формируем словарь conn_map, в него записываем файловые дескрипторы и объекты наших соединений:\n",
    "# Неблокирующий ввод/вывод, обучающий пример\n",
    "import socket\n",
    "import select\n",
    "sock = socket.socket()\n",
    "sock.bind((\"\", 10001))\n",
    "sock.listen()\n",
    "# как обработать запросы для conn1 и conn2\n",
    "# одновременно без потоков?\n",
    "conn1, addr = sock.accept()\n",
    "conn2, addr = sock.accept()\n",
    "conn1.setblocking(0)\n",
    "conn2.setblocking(0)\n",
    "epoll = select.epoll()\n",
    "epoll.register(conn1.fileno(), select.EPOLLIN | select.EPOLLOUT)\n",
    "epoll.register(conn2.fileno(), select.EPOLLIN | select.EPOLLOUT)\n",
    "conn_map = {\n",
    "conn1.fileno(): conn1,\n",
    "conn2.fileno(): conn2\n",
    "}\n",
    "Давайте рассмотрим цикл обработки событий для нашего epoll, который иногда называют event loop. Итак, мы в бесконечном цикле постоянно опрашиваем наш объект epoll.\n",
    "Это системный вызов, который нам возвращает список событий, и эти события содержат\n",
    "файловый дескриптор и непосредственно то событие, которое произошло с этим файловым дескриптором. После того как epoll вернул этот список, мы должны проверить,\n",
    "что за событие пришло, из нашего словаря получить нужный объект для работы с ним и\n",
    "выполнить определённые операции. В данном случае, например, мы читаем данные из\n",
    "этого сокета и выводим их в консоль. Если пришло событие, которое говорит нам, что сокет готов принять данные от нас, мы должны записать данные в этот сокет:\n",
    "28\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Неблокирующий ввод/вывод, обучающий пример\n",
    "# Цикл обработки событий в epoll\n",
    "while True:\n",
    "events = epoll.poll(1)\n",
    "for fileno, event in events:\n",
    "if event & select.EPOLLIN:\n",
    "# обработка чтения из сокета\n",
    "data=conn_map[fileno].recv(1024)\n",
    "print(data.decode(\"utf8\"))\n",
    "elif event & select.EPOLLOUT:\n",
    "# обработка записи в сокет\n",
    "conn_map[fileno].send(\"pong\".encode(\"utf8\"))\n",
    "Такой код иногда называют асинхронным программированием, или мультиплексированием ввода/вывода. Код уже не выглядит слишком простым (хотя в нем нет создания\n",
    "потоков или процессов, нет обработки закрытия сокетов, отсутствует обработка новых\n",
    "входящих соединений). Также мы не тратим память на создание процессов, нет расходов\n",
    "на создание потоков и их синхронизацию, нет проблем с GIL.\n",
    "Но если код будет решать настоящие задачи, то увеличится кол-во операторов if или\n",
    "callback-ов. Кроме того, нам придётся изменять код, если в обработке запроса появятся\n",
    "вызовы сторонних библиотек. Для этого есть решение: спрятать вызовы select.epoll\n",
    "в функции библиотеки.\n",
    "Так поступили и написали существующие в Python фреймворки. Наиболее популярным\n",
    "был долгое время фреймворк Twisted, его работа очень похожа на наш пример, но код на\n",
    "Twisted, затем Gevent и Tornado. После Tornado в Python3 появился фреймворк asyncio, и\n",
    "он сейчас является мейнстримом. В его основе, в принципе, лежит то же самое, что и в\n",
    "Tornado, но тем не менее asyncio поставляется вместе с Python3 Core и также основан на\n",
    "работе генераторов. Его поддерживают официальные сообщества, и поэтому все наши\n",
    "дальнейшие разговоры о программировании в один поток будут привязаны к фреймворку\n",
    "asyncio.\n",
    "5.4.2. Итераторы и генераторы, в чём разница\n",
    "Чтобы лучше понимать, как устроен asyncio, нужно сначала разобраться в том, как устроены генераторы и итераторы, в чём их сходство и различие.\n",
    "Давайте рассмотрим пример с итератором, который генерирует последовательность 0,\n",
    "1, 2. Чтобы решить эту задачу, необходимо создать класс и переоределить у него методы\n",
    "__init__, __iter__ и __next__. Если мы вызовем итератор в цикле for, то сначала вызовется метод __iter__, а затем будет последовательно вызываться метод __next__.\n",
    "Когда выполнится условие if self.current >= self.top вызовется исключение, и\n",
    "итератор прекратит работу:\n",
    "29\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Итераторы\n",
    "class MyRangeIterator:\n",
    "def __init__(self, top):\n",
    "self.top = top\n",
    "self.current = 0\n",
    "def __iter__(self):\n",
    "return self\n",
    "def __next__(self):\n",
    "if self.current >= self.top:\n",
    "raise StopIteration\n",
    "current = self.current\n",
    "self.current += 1\n",
    "return current\n",
    "counter = MyRangeIterator(3)\n",
    "counter\n",
    "<__main__.MyRangeIterator object at 0xb671b5cc>\n",
    "for it in counter:\n",
    "print(it)\n",
    "0\n",
    "1\n",
    "2\n",
    "Чтобы создать генератор, нужно написать обычную функцию с командой yield. Реализуем тот же фукционал с помощью генератора. На самом деле, когда мы вызовем эту\n",
    "функцию, создастся объект, по которому можно итерироваться:\n",
    "# Генераторы\n",
    "def my_range_generator(top):\n",
    "current = 0\n",
    "while current < top:\n",
    "yield current\n",
    "current += 1\n",
    "counter = my_range_generator(3)\n",
    "counter\n",
    "<generator object my_range_generator at 0xb67170ec>\n",
    "30\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "for it in counter:\n",
    "print(it)\n",
    "0\n",
    "1\n",
    "2\n",
    "На самом деле, при вызове yield генератор замораживает свой стек и все значения\n",
    "локальных переменных в объекте counter. При повторном вызове функций стек и локальные переменные восстанавливаются, и мы продолжаем выполнять следующие инструкции.\n",
    "Подводя итоги, скажем, что в генераторах заложены большие возможности для написания concurrency кода.\n",
    "5.4.3. Генераторы и сопрограммы\n",
    "В этом разделе мы познакомимся с сопрограммами (или корутинами) и выясним, в чем\n",
    "отличие и сходство между генераторами и сопрограммами в Python. Предположим, наша\n",
    "цель — фильтровать входной поток при помощи функции grep. В функцию grep мы передаем строку-паттерн, далее мы должны в эту функцию перевадать строчки и выводить\n",
    "на экран только те из них, в которых присутствует заданный паттерн. Давайте реализуем\n",
    "эту функцию как корутину.\n",
    "Мы в бесконечном цикле вызываем такую конструкцию line присвоить yield (в отличие от генераторов в корутинах мы переменной присваиваем результат работы конструкции yield). В данном случае функция заморозит своё состояние и будет ожидать ввода\n",
    "данных при помощи метода send. Итак, если мы вызовем функцию grep, будет создана\n",
    "корутина. Для того чтобы запустить нашу корутину, необходимо вызвать метод next. После того, как метод next будет вызван, запустится код нашей функции, выведется строчка start grep, запустится бесконечный цикл, код дойдет до инструкции yield, и здесь\n",
    "управление вернется в основной поток. После этого в основном потоке мы отправляем\n",
    "данные нашей корутине, и код функции выполняется дальше:\n",
    "# Сопрограммы (корутины)\n",
    "def grep(pattern):\n",
    "print(\"start grep\")\n",
    "while True:\n",
    "line = yield\n",
    "if pattern in line:\n",
    "print(line)\n",
    "g = grep(\"python\")\n",
    "next(g) # g.send(None)\n",
    "start grep\n",
    "31\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "g.send(\"golang is better?\")\n",
    "g.send(\"python is simple!\")\n",
    "python is simple!\n",
    "Таким образом, можно сделать вывод, что генераторы производят значения, а корутины их потребляют с помощью одного и того же метода yield.\n",
    "Иногда необходимо остановить запущенную корутину. Делается это при помощи вызова метода close для объекта корутины. Метод close будет вызван автоматически сборщиком мусора, но если нам нужно самим остановить корутину, то можно руками вызвать\n",
    "метод close. Метод close сгенерирует исключение генератора в том месте, где функция\n",
    "заморозила свое значение. Это исключение нельзя игнорировать, его нужно обрабатывать — например, при помощи блока try except:\n",
    "# Сопрограммы, вызов метода close()\n",
    "def grep(pattern):\n",
    "print(\"start grep\")\n",
    "try:\n",
    "while True:\n",
    "line = yield\n",
    "if pattern in line:\n",
    "print(line)\n",
    "except GeneratorExit:\n",
    "print(\"stop grep\")\n",
    "g = grep(\"python\")\n",
    "next(g) # g.send(None)\n",
    "start grep\n",
    "g.send(\"python is the best!\")\n",
    "python is the best!\n",
    "g.close()\n",
    "stop grep\n",
    "Иногда необходимо передать исключения в саму корутину. Это делается при помощи\n",
    "вызова метода throw. Пример точно такой же:\n",
    "32\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# Сопрограммы, генерация исключений\n",
    "def grep(pattern):\n",
    "print(\"start grep\")\n",
    "try:\n",
    "while True:\n",
    "line = yield\n",
    "if pattern in line:\n",
    "print(line)\n",
    "except GeneratorExit:\n",
    "print(\"stop grep\")\n",
    "g = grep(\"python\")\n",
    "next(g) # g.send(None)\n",
    "g.send(\"python is the best!\")\n",
    "g.throw(RuntimeError, \"something wrong\")\n",
    "Traceback (most recent call last):\n",
    "File \"<stdin>\", line 1, in <module>\n",
    "RuntimeError: something wrong\n",
    "Давайте посмотрим еще более сложный пример. У нас есть корутина grep, содержащая внутри инструкцию yield, и мы хотим вызвать корутину grep в другой корутине.\n",
    "Как это сделать? Если мы напишем код, который приведен на слайде, и потом сделаем\n",
    "данный вызов, то будет ли переменная g являться корутиной? Так как она не содержит\n",
    "инструкции yield, она выполнится сразу, т.к. будет являться обычной функцией:\n",
    "# Вызовы сопрограмм, PEP 380\n",
    "def grep(pattern):\n",
    "print(\"start grep\")\n",
    "while True:\n",
    "line = yield\n",
    "if pattern in line:\n",
    "print(line)\n",
    "def grep_python_coroutine():\n",
    "g = grep(\"python\")\n",
    "next(g)\n",
    "g.send(\"python is the best!\")\n",
    "g.close()\n",
    "g = grep_python_coroutine() # is g coroutine?\n",
    "start grep\n",
    "python is the best!\n",
    "33\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Для того чтобы было удобно вызывать из одних корутин другие, в Python разработали стандарт PEP 0380 и в Python 3 его реализовали. В новом стандарте появилась инструкция yield from. При помощи неё можно выполнить делегирование вызова одной\n",
    "корутины в другой. Наш пример можно переписать следующим образом мы используем\n",
    "инструкцию yield from и указываем объект в виде другой корутины:\n",
    "# Сопрограммы, yield from PEP 0380\n",
    "def grep(pattern):\n",
    "print(\"start grep\")\n",
    "while True:\n",
    "line = yield\n",
    "if pattern in line:\n",
    "print(line)\n",
    "def grep_python_coroutine():\n",
    "g = grep(\"python\")\n",
    "yield from g\n",
    "g = grep_python_coroutine() # is g coroutine?\n",
    "g\n",
    "<generator object grep_python_coroutine at 0x7f027eec03b8>\n",
    "g.send(None)\n",
    "start grep\n",
    "g.send(\"python wow!\")\n",
    "python wow!\n",
    "Теперь, если мы попробуем вызвать нашу функцию grep_python_coroutine, она\n",
    "будет являться корутиной или генератором, и для того, чтобы продолжить и выполнить\n",
    "код, который находится у нее внутри, необходимо вызвать метод send, передать туда\n",
    "значение None и далее вызвать метод send и передать нужную строчку. Таким образом,\n",
    "в Python 3 стало очень легко и удобно вызывать из одной корутины другую.\n",
    "Для обычных генераторов инструкцию yield from можно использовать как замену\n",
    "цикла for, внутри которого вызывается инструкция yield. Рассмотрим пример. Например, у нас есть два объекта, по которым возможно осуществлять итерацию — a и b. Далее\n",
    "в цикле вызываем функцию chain, передаем туда эти списки и выводим то, что нам генерирует наша функция chain. В функции chain мы используем конструкцию yield from\n",
    "и передаем туда объект, по которому возможна итерация. Функция the_same_chain работает так же, но реализована при помощи циклов:\n",
    "34\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# PEP 380, генераторы\n",
    "def chain(x_iterable, y_iterable):\n",
    "yield from x_iterable\n",
    "yield from y_iterable\n",
    "def the_same_chain(x_iterable, y_iterable):\n",
    "for x in x_iterable:\n",
    "yield x\n",
    "for y in y_iterable:\n",
    "yield y\n",
    "a = [1, 2, 3]\n",
    "b = (4, 5)\n",
    "for x in chain(a, b):\n",
    "print(x)\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "5.4.4. Первые шаги с asyncio\n",
    "asyncio — это библиотека, которая стала частью Python 3. Она отвечает за неблокирующий ввод/вывод, на этом фреймворке можно написать сервис, который работает с\n",
    "десятками тысяч соединений одновременно. В основе работы этого фреймворка лежат\n",
    "генераторы и корутины, о чем мы уже говорили в предыдущих видео.\n",
    "В следующем примере мы объявляем функцию и добавляем к этой функции декоратор\n",
    "asyncio.coroutine, тем самым делая нашу функцию корутиной. Далее, мы в бесконечном цикле выполняем вывод строчки \"Hello World\" в консоль и делаем вызов yield\n",
    "from asyncio.sleep(1.0), то есть \"засыпаем\" на одну секунду. Обратите внимание,\n",
    "что мы используем не привычный нам time.sleep вызов, а специальную конструкцию\n",
    "yield from для того, чтобы наша корутина приостановила свою работу, тем самым давая возможность поисполняться другим корутинам:\n",
    "35\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# asyncio, Hello World\n",
    "import asyncio\n",
    "@asyncio.coroutine\n",
    "def hello_world():\n",
    "while True:\n",
    "print(\"Hello World!\")\n",
    "yield from asyncio.sleep(1.0)\n",
    "Весь код в asyncio строится на основе понятия цикла обработки событий или, как еще\n",
    "его иногда называют, event loop. event loop — это своего рода планировщик задач или\n",
    "корутин, которые в нем исполняются. Он отвечает за ввод/вывод, управление сигналами, всеми сетевыми операциями и переключает контекст между всеми корутинами, которые в нем зарегистрированы и выполняются. Если одна корутина ожидает завершения\n",
    "какой-то сетевой операции, то в этот момент event loop может переключиться на другую корутину и продолжить ее выполнение. Продолжим наш пример. При помощи вызова\n",
    "asyncio.get_event_loop мы получаем цикл обработки событий. Это объект, который\n",
    "исполняет корутины (обычные функции с помощью него исполнять нельзя, нужно использовать именно корутины):\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(hello_world())\n",
    "Hello World!\n",
    "Hello World!\n",
    "...\n",
    "Для того, чтобы завершить работу с циклом обработки событий, необходимо вызвать\n",
    "метод close для нашего объекта loop:\n",
    "loop.close()\n",
    "Начиная с версии Python 3.5, появился новый PEP 492, в котором был введен специальный синтаксис для написания корутин — с инструкцииями async def и await. Этот\n",
    "синтаксис выглядит более лаконично и красиво по сравнению с предыдущим, кроме того, объявление функции через конструкцию async def гарантирует нам, что эта функция\n",
    "является корутиной. Если мы используем этот синтаксис, то внутри мы не можем использовать конструкцию yield from, мы обязаны использовать вызов await:\n",
    "36\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "# asyncio, async def / await; PEP 492 Python3.5\n",
    "import asyncio\n",
    "async def hello_world():\n",
    "while True:\n",
    "print(\"Hello World!\")\n",
    "await asyncio.sleep(1.0)\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(hello_world())\n",
    "loop.close()\n",
    "Давайте рассмотрим более сложный пример и напишем свой TCP-сервер, который\n",
    "обрабатывает несколько входящих соединений одновременно. Итак, мы получаем наш\n",
    "event loop, делаем вызов start_server, передаём в этот вызов корутину. В функциию\n",
    "start_server мы должны еще передать параметры в виде хоста и порта, на котором мы\n",
    "будем слушать соединение. Далее мы запускаем установку этого соединения и делаем\n",
    "вызов loop.run_forever. Тем самым мы будем обрабатывать все входящие соединения, и после того, как мы заакцептили соединение, для каждого соединения будет создана\n",
    "отдельная корутина, и в этой корутине будет выполнена наша функция. При помощи конструкции await reader мы можем читать данные из нашего сокета, и также существует\n",
    "writer (если нам будет необходимо, мы сможем записывать данные в наш сокет):\n",
    "# asyncio, tcp сервер\n",
    "import asyncio\n",
    "async def handle_echo(reader, writer):\n",
    "data = await reader.read(1024)\n",
    "message = data.decode()\n",
    "addr = writer.get_extra_info(\"peername\")\n",
    "print(\"received %r from %r\" % (message, addr))\n",
    "writer.close()\n",
    "loop = asyncio.get_event_loop()\n",
    "coro = asyncio.start_server(handle_echo, \"127.0.0.1\", 10001,\n",
    "loop=loop)\n",
    "server = loop.run_until_complete(coro)\n",
    "try:\n",
    "loop.run_forever()\n",
    "except KeyboardInterrupt:\n",
    "pass\n",
    "server.close()\n",
    "loop.run_until_complete(server.wait_closed())\n",
    "loop.close()\n",
    "37\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "Давайте рассмотрим код клиента, который тоже может быть асинхронным. Допустим,\n",
    "мы клиент будет передавать строчку. В корутину tcp_echo_client передаём эту строчку\n",
    "(message) и наш event loop. Далее, для того, чтобы создать соединение, мы должны вызвать метод asyncio.open_connection. В этом вызове мы должны отправить адресную\n",
    "пару и вызов await вернет нам reader и writer. Это два объекта, при помощи которых\n",
    "можно взаимодействовать с нашим удаленным сервером. То есть, при помощи объекта\n",
    "reader можно читать данные с сервера, при помощи объекта writer можно записывать\n",
    "данные на сервер:\n",
    "# asyncio, tcp клиент\n",
    "import asyncio\n",
    "async def tcp_echo_client(message, loop):\n",
    "reader, writer = await asyncio.open_connection(\"127.0.0.1\",\n",
    "10001, loop=loop)\n",
    "print(\"send: %r\" % message)\n",
    "writer.write(message.encode())\n",
    "writer.close()\n",
    "loop = asyncio.get_event_loop()\n",
    "message = \"hello World!\"\n",
    "loop.run_until_complete(tcp_echo_client(message, loop))\n",
    "loop.close()\n",
    "Вы можете легко создать несколько таких асинхронных клиентов и одновременно выполнять запросы на разные сервера, при этом не делая никаких потоков или процессов.\n",
    "Это очень удобно, просто, и код получается достаточно производительным.\n",
    "5.4.5. Работа с asyncio\n",
    "В этом последнем разделе мы обсудим, что такое asyncio.Future и поговорим о том,\n",
    "как создавать объекты типа asyncio.Task. Также мы рассмотрим проблему запуска синхронных функций в цикле обработки событий и немного обсудим библиотеки, которые существуют для работы с фреймворком asyncio.\n",
    "Давайте перейдем к примеру. В нём мы объявляем корутину slow_operation, в неё\n",
    "передаем некий объект asyncio.Future(), который исполняется, и его выполнение ещё\n",
    "не завершено. Интерфейс этого объекта целиком и полностью соответствует интерфейсу\n",
    "concurrent.futures.Future (мы разбирали его при знакомстве с потоками).\n",
    "В корутине мы выполнили sleep на одну секунду, и после этого при помощи set_result\n",
    "выставили результат в наш объект типа future:\n",
    "38\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "### asyncio.Future, аналог concurrent.futures.Future\n",
    "import asyncio\n",
    "async def slow_operation(future):\n",
    "await asyncio.sleep(1)\n",
    "future.set_result(\"Future is done!\")\n",
    "loop = asyncio.get_event_loop()\n",
    "future = asyncio.Future()\n",
    "asyncio.ensure_future(slow_operation(future))\n",
    "loop.run_until_complete(future)\n",
    "print(future.result())\n",
    "loop.close()\n",
    "Future is done!\n",
    "Обратите внимание — в основной программе мы создаем объект future, далее мы\n",
    "создаем нашу корутину при помощи ensure_future, а в основном цикле обработки событий мы ожидаем завершения объекта future (а не функции slow_operation!). Таким\n",
    "образом, при помощи объектов класса future можно выстраивать цепочки не только из\n",
    "двух объектов, но и более сложные цепочки, и очень удобно дожидаться завершения выполнения всех объектов.\n",
    "Давайте посмотрим, как можно запустить несколько корутин в одном event loop. Для\n",
    "этого, как правило, используется объект типа asyncio.Task, который является наследником класса asyncio.Future с рядом дополнительных методов. Итак, напрямую объект\n",
    "типа asyncio.Task создавать не нужно, стоит использовать метод create_task и передавать в него корутину (у каждого объекта типа Task есть собственная корутина, которую\n",
    "он исполняет). Итак, мы создаем список из двух тасков. Запоминаем его в виде списка\n",
    "объектов, и далее при помощи метода asyncio.wait мы исполняем список наших тасков в event loop:\n",
    "39\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "### asyncio.Task, запуск нескольких корутин\n",
    "import asyncio\n",
    "async def sleep_task(num):\n",
    "for i in range(5):\n",
    "print(f\"process task: {num} iter: {i}\")\n",
    "await asyncio.sleep(1)\n",
    "return num\n",
    "# ensure_future or create_task\n",
    "loop = asyncio.get_event_loop()\n",
    "task_list = [loop.create_task(sleep_task(i)) for i in range(2)]\n",
    "loop.run_until_complete(asyncio.wait(task_list))\n",
    "loop.close()\n",
    "process task: 0 iter: 0\n",
    "process task: 1 iter: 0\n",
    "process task: 0 iter: 1\n",
    "process task: 1 iter: 1\n",
    "process task: 0 iter: 2\n",
    "process task: 1 iter: 2\n",
    "process task: 0 iter: 3\n",
    "process task: 1 iter: 3\n",
    "process task: 0 iter: 4\n",
    "process task: 1 iter: 4\n",
    "Мы видим, что у нас сначала один таск выполняет нулевую итерацию, затем второй\n",
    "таск с номером выполняет свою нулевую итерацию и т.д. То есть корутины исполняются\n",
    "в event loop-е одновременно, а код при этом последовательный.\n",
    "Также можно выполнить несколько тасков при промощи удобной функции\n",
    "asyncio.gather, которая позволяет не вызывать отдельно метод create_task:\n",
    "loop.run_until_complete(asyncio.gather(sleep_task(10),\n",
    "sleep_task(20)))\n",
    "Но что если нам необходимо исполнить синхронную функцию в event loop? Как правило, таких задач не должно возникать, но если вдруг они и возникли, то они будут представлять из себя небольшую сложность. event loop постоянно переключает контекст между всеми нашими корутинами и исполняет их последовательно — пока одна корутина\n",
    "ожидает ввода-вывода, вторую корутину event loop благополучно исполняет. Если код,\n",
    "который будет исполняться в корутине, будет блокирующим, то event loop не сможет делать переключения контекста. Для решения этой проблемы в asyncio существует метод\n",
    "40\n",
    "Курс \"Программирование на Python\", Mail.Ru Group\n",
    "run_in_executor. Он означает запустить код буквально в пуле потоков, который внутри\n",
    "этого event loop-а автоматически будет создан (можно использовать собственный пул потоков или уже готовый по умолчанию).\n",
    "На этом примере можно наблюдать, как функция urlopen, которая открывает некий\n",
    "url, который ей передали, скачивает результаты в отдельном потоке. Для этого мы вызываем метод run_in_executor. Внутри него будет создано нужное количество потоков,\n",
    "и наша функция sync_get_url с параметром url будет выполнена в отдельном потоке. Для того, чтобы дождаться результата выполнения функции в отдельном потоке, мы\n",
    "используем конструкцию await и передаем туда объект future. Мы будем открывать\n",
    "страничку google.com и выводить на экран количество байт, которые она занимает:\n",
    "# loop.run_in_executor, запуск в отдельном потоке\n",
    "import asyncio\n",
    "from urllib.request import urlopen\n",
    "# a synchronous function\n",
    "def sync_get_url(url):\n",
    "return urlopen(url).read()\n",
    "async def load_url(url, loop=None):\n",
    "future = loop.run_in_executor(None, sync_get_url, url)\n",
    "response = await future\n",
    "print(len(response))\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(load_url(\"https://google.com\", loop=loop))\n",
    "11055\n",
    "Как правило, такие задачи будут возникать у вас, если в некоторой библиотеке не будет\n",
    "поддержки работы с asyncio. Это может сказаться негативно на производительности,\n",
    "потому что, как мы помним, потоки в Python запускаются и работают с ограничением GIL. В\n",
    "последнее время появляются библиотеки с поддержкой asyncio — aiohttp, aiomysql,\n",
    "aiomcache и многие другие."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
